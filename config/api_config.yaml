gpt-5:
    model: gpt-5
    endpoints: null
    api_type: gpt5
    parallel: 32
    temperature: 1

gpt-5-non-reasoning:
    model: gpt-5
    endpoints: null
    api_type: gpt5
    parallel: 32
    temperature: 1
    reasoning:
        effort: low
    text:
        verbosity: low

gpt-4.1-2025-04-14:
    model: gpt-4.1-2025-04-14
    endpoints: null
    api_type: openai
    parallel: 64
    max_tokens: 32000
    temperature: 0.0

# JUDGE MODEL USING RECOMMENDED SETTINGS FROM README
gpt-4.1:
    model: gpt-4.1
    endpoints: null
    api_type: openai
    parallel: 64
    max_tokens: 32000
    temperature: 0.0

gemini-2.5-flash-thinking:
    model: gemini-2.5-flash
    endpoints: null
    api_type: gemini
    parallel: 50

gemini-2.5-pro:
    model: gemini-2.5-flash
    endpoints: null
    api_type: gemini
    parallel: 50

gemini-2.5:
    model: gemini-2.5-pro-preview-03-25
    endpoints: null
    api_type: gemini
    parallel: 50

deepseek-v3.2-exp:
    model: deepseek-chat
    endpoints:
        - api_key: "API_KEY"
    api_type: deepseek
    parallel: 32
    max_tokens: 8192

claude-sonnet-4-5-20250929-thinking:
    model: claude-sonnet-4-5-20250929
    endpoints: null
    max_tokens: 20000
    api_type: anthropic
    parallel: 25
    thinking: false

claude-3-7-sonnet-20250219-thinking-16k:
    model: claude-3-7-sonnet-20250219
    endpoints: null
    max_tokens: 20000
    budget_tokens: 16000
    api_type: anthropic_thinking
    parallel: 32

grok-4-fast-non-reasoning:
    model: grok-4-fast-non-reasoning
    endpoints:
        - api_base: https://api.x.ai/v1
          api_key: "API_KEY"
    api_type: openai
    parallel: 32
    max_tokens: 8192
    temperature: 0.0

mistral-medium-2508:
    model: mistral-medium-2508
    endpoints: null
    api_type: mistral
    parallel: 32
    max_tokens: 8192
    temperature: 0.0


qwen3-30b-a3b:
    model: Qwen/Qwen3-30B-A3B-Instruct-2507
    endpoints:
        - api_base: http://0.0.0.0:8000/v1
          api_key: '-'
    api_type: openai
    parallel: 32
    max_tokens: 8196
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0.0

qwen3-235b-orig:
    model: /home/ubuntu/locai-llm-training/models/Qwen3-235B-A22B-Instruct-2507 
    endpoints:
        - api_base: http://0.0.0.0:8000/v1
          api_key: '-'
    api_type: openai
    parallel: 16
    max_tokens: 8196
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0.0

qwen3-235b-orig-run-2:
    model: /home/ubuntu/locai-llm-training/models/Qwen3-235B-A22B-Instruct-2507 
    endpoints:
        - api_base: http://0.0.0.0:8000/v1
          api_key: '-'
    api_type: openai
    parallel: 16
    max_tokens: 8196
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0.0

L1-large:
    model: ../finetuning_ms_swift/megatron_output/Qwen3-235B-A22B-Instruct-2507/v23-20251014-160027-hf
    endpoints:
        - api_base: http://0.0.0.0:8000/v1
          api_key: '-'
    api_type: openai
    parallel: 16
    max_tokens: 8196
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0.0


qwen3-235b-v27:
    model: ../finetuning_ms_swift/megatron_output/Qwen3-235B-A22B-Instruct-2507/v27-20251017-070136-hf
    endpoints:
        - api_base: http://0.0.0.0:8000/v1
          api_key: '-'
    api_type: openai
    parallel: 16
    max_tokens: 8196
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0.0

qwen-235b-v23:
    model: ../finetuning_ms_swift/megatron_output/Qwen3-235B-A22B-Instruct-2507/v23-20251014-160027-hf
    endpoints:
        - api_base: http://0.0.0.0:8000/v1
          api_key: '-'
    api_type: openai
    parallel: 16
    max_tokens: 8196
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0.0


qwen3-235b-v23-fp8:
    model: ../quantize/quantized/Qwen3-235B-A22B-Instruct-2507/v23-20251014-160027-hf-FP8
    endpoints:
        - api_base: http://0.0.0.0:8000/v1
          api_key: '-'
    api_type: openai
    parallel: 16
    max_tokens: 8196
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0.0

    